# ğŸ§  NLP Text Classification Pipeline ğŸš€

This project provides a complete **NLP text classification pipeline** using supervised machine learning techniques. It includes **training, experiment tracking with MLflow**, an **API using FastAPI** for real-time predictions, and a **CI/CD pipeline via GitHub Actions**.

---

## ğŸ” Project Goal

The goal is to automatically predict the **sentiment** (positive or negative) of a given text review. The pipeline combines:

- **Text vectorization** (TF-IDF)
- **Supervised model** (Logistic Regression)
- **Experiment tracking with MLflow**
- **API deployment via FastAPI**
- **Unit tests with pytest**
- **CI/CD automation via GitHub Actions**

---

## ğŸ§° Tech Stack

- `Python 3.10` â€“ core language  
- `pandas` â€“ data handling  
- `scikit-learn` â€“ model training and TF-IDF vectorization  
- `MLflow` â€“ experiment and model tracking  
- `FastAPI` â€“ REST API  
- `Uvicorn` â€“ ASGI server  
- `pytest` â€“ unit testing  
- `GitHub Actions` â€“ continuous integration (CI/CD)
- `Docker & Docker Compose` â€“ containerization and orchestration

---

## ğŸ“ Project Structure

```
nlp_text_classification_pipeline/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/sample_reviews_200.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                # FastAPI app
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ model_training.py     # MLflow logging
â”‚   â””â”€â”€ predict.py            # Load model and predict
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_predict.py       # Unit tests
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/ci-cd.yml   # CI pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

1. **Clone the repository**  
```bash
git clone https://github.com/your-username/nlp_text_classification_pipeline.git
cd nlp_text_classification_pipeline
```

2. **Create virtual environment**  
```bash
python -m venv .venv
source .venv/bin/activate        # Linux/Mac
.venv\Scripts\activate         # Windows
```

3. **Install dependencies**  
```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸â€â™‚ï¸ Train the Model

```bash
python -m src.model_training
```

This will:
- Preprocess and vectorize the text data
- Train a logistic regression classifier
- Automatically log the model, vectorizer, and metrics to **MLflow**

To launch the MLflow tracking UI:
```bash
mlflow ui
```
Visit: [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸš€ Run the FastAPI Server

```bash
uvicorn src.app:app --reload
```

Open the interactive API docs at: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ§ª Run Tests

```bash
pytest
```

You can also test a live prediction via curl:
```bash
curl -X POST "http://127.0.0.1:8000/predict" -H "Content-Type: application/json" -d "{\"text\": \"I love this movie!\"}"
```

---

## ğŸ³ Docker & Docker Compose

To run the project using Docker:

1. **Build and start containers**
```bash
docker-compose up --build
```

2. **Access the services:**
- FastAPI: [http://localhost:8000/docs](http://localhost:8000/docs)
- MLflow: [http://localhost:5000](http://localhost:5000)

Example `docker-compose.yml`:
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    command: uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload

  mlflow:
    image: ghcr.io/mlflow/mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlruns
    volumes:
      - ./mlruns:/mlruns
```

---

## ğŸ”„ CI/CD with GitHub Actions

The project uses GitHub Actions to:

- âœ… Install dependencies  
- âœ… Run unit tests  
- âœ… Trigger on push or pull request to the `main` branch  

See the workflow file at `.github/workflows/ci-cd.yml`.

---

## ğŸŒ± Future Enhancements

- Integrate a lightweight **LLM** from Hugging Face (e.g. `distilbert-base-uncased`)
- Add more advanced preprocessing (lemmatization, emoji/text cleaning)
- Deploy API via **Docker**, **Render**, or **Railway**

---

## ğŸ‘¨â€ğŸ’» Author

**Sofian OUASS**  
Big Data Engineer & Data Scientist  
ğŸ“ Montpellier, France  
ğŸ”— [GitHub Profile](github.com/sofian-30)
